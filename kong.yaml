---
# Source: kong/templates/ingress-controller-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-kong
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
automountServiceAccountToken: true
---
# Source: kong/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "harbor"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.6.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "Q3JSQmZDNVlXQg=="
  password: "RXF0dmFnaEZobw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: kong/templates/kong-script-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-kong-scripts
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
data:
  kong-container-health.sh: |-
    #!/bin/bash

    set -o errexit
    set -o nounset
    set -o pipefail

    # Load libraries
    . /opt/bitnami/scripts/libos.sh
    . /opt/bitnami/scripts/libkong.sh

    # Load Kong environment variables
    . /opt/bitnami/scripts/kong-env.sh

    is_kong_running

  ingress-container-wait-for-kong.sh: |-
    #!/bin/bash

    echo "Waiting for the Kong container to be ready"
    if wait-for-port --timeout=300 --host=127.0.0.1 --state=inuse 8000; then
      echo "Kong container ready"
    else
      echo "Kong not ready after 300 seconds"
      exit 1
    fi

  ingress-container-start.sh: |-
    #!/bin/bash

    . /health/ingress-container-wait-for-kong.sh

    kong-ingress-controller
---
# Source: kong/templates/ingress-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-kong
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - services/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - configuration.konghq.com
  resources:
  - ingressclassparameterses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongconsumers
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongconsumers/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongingresses/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongplugins
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongplugins/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - configuration.konghq.com
  resources:
  - tcpingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - tcpingresses/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - configuration.konghq.com
  resources:
  - udpingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - udpingresses/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - ingresses/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongclusterplugins
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - configuration.konghq.com
  resources:
  - kongclusterplugins/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
---
# Source: kong/templates/ingress-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-kong
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-kong
subjects:
  - kind: ServiceAccount
    name: release-name-kong
    namespace: harbor
---
# Source: kong/templates/ingress-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-kong
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - pods
      - secrets
      - namespaces
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - "kong-ingress-controller-leader-kong-kong"
    verbs:
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - endpoints
    verbs:
      - get
  # Begin KIC 2.x leader permissions
  - apiGroups:
      - ""
      - coordination.k8s.io
    resources:
      - configmaps
      - leases
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
---
# Source: kong/templates/ingress-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-kong
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-kong
subjects:
  - kind: ServiceAccount
    name: release-name-kong
    namespace: harbor
---
# Source: kong/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "harbor"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.6.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: kong/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "harbor"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.6.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: kong/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-kong
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - port: 80
      targetPort: http-proxy
      protocol: TCP
      name: http-proxy
      nodePort: null
    - port: 443
      targetPort: https-proxy
      protocol: TCP
      name: https-proxy
      nodePort: null
  selector:
    app.kubernetes.io/name: kong
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: server
---
# Source: kong/templates/dep-ds.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-kong
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: kong
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: server
  strategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kong
        helm.sh/chart: kong-9.4.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: server
      annotations:
        checksum/configmap-kong: bd2ac948fed263c32d30c43c61c1da6ac22725a2afde09852374b96a727f04b0
    spec:
      
      serviceAccountName: release-name-kong
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kong
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: server
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      containers:
        - name: kong
          image: docker.io/bitnami/kong:3.3.1-debian-11-r0
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: KONG_DATABASE
              value: "postgres"
            - name: KONG_PG_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: KONG_PG_HOST
              value: "release-name-postgresql"
            - name: KONG_PG_PORT
              value: "5432"
            - name: KONG_PG_USER
              value: "kong"
          ports:
            - name: http-proxy
              containerPort: 8000
              protocol: TCP
            - name: https-proxy
              containerPort: 8443
              protocol: TCP
            - name: http-admin
              containerPort: 8001
              protocol: TCP
            - name: https-admin
              containerPort: 8444
              protocol: TCP
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/bash
                - -ec
                - /health/kong-container-health.sh
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/bash
                - -ec
                - /health/kong-container-health.sh
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - kong quit
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: health
              mountPath: /health
        - name: kong-ingress-controller
          image: docker.io/bitnami/kong-ingress-controller:2.10.2-debian-11-r1
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - bash
            - -ec
            - /health/ingress-container-start.sh
          env:
            - name: CONTROLLER_KONG_ADMIN_URL
              value: http://127.0.0.1:8001
            - name: CONTROLLER_PUBLISH_SERVICE
              value: "harbor/release-name-kong"
            - name: CONTROLLER_INGRESS_CLASS
              value: kong
            - name: CONTROLLER_ELECTION_ID
              value: kong-ingress-controller-leader-kong
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http-health
              containerPort: 10254
              protocol: TCP
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: "/healthz"
              port: http-health
              scheme: HTTP
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: "/healthz"
              port: http-health
              scheme: HTTP
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: health
              mountPath: /health
      volumes:
        - name: health
          configMap:
            name: release-name-kong-scripts
            defaultMode: 0755
---
# Source: kong/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "harbor"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.6.5
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.6.5
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:14.8.0-debian-11-r24
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "kong"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "kong"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "kong" -d "dbname=kong" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "kong" -d "dbname=kong" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: kong/templates/migrate-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-kong-migrate
  namespace: harbor
  labels:
    app.kubernetes.io/name: kong
    helm.sh/chart: kong-9.4.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: server
  annotations:
    helm.sh/hook: post-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kong
        helm.sh/chart: kong-9.4.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: migration
    spec:
      
      restartPolicy: OnFailure
      containers:
        - name: kong-migrate
          image: docker.io/bitnami/kong:3.3.1-debian-11-r0
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: KONG_MIGRATE
              value: "yes"
            - name: BITNAMI_DEBUG
              value: "false"
            - name: KONG_EXIT_AFTER_MIGRATE
              value: "yes"
            - name: KONG_DATABASE
              value: "postgres"
            - name: KONG_PG_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: KONG_PG_HOST
              value: "release-name-postgresql"
            - name: KONG_PG_PORT
              value: "5432"
            - name: KONG_PG_USER
              value: "kong"
          resources:
            limits: {}
            requests: {}
